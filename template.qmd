---
title: "Supplement Template for MCP in GSD"
---

```{r setup, include=FALSE}
require(tidyverse)
require(gsDesign)
require(gsMCPLite)
require(gMCP)
require(mvtnorm)
require(kableExtra)
require(knitr)
# require(lubridate)

knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    fig.width = 6.5,
    fig.height = 4.5,
    message = FALSE,
    warning = FALSE
)
options(width = 58)

source("./utils_MT_in_grSeq.R")
```

```{r input, fig.height=5, fig.width=5, fig.align="center"}
###############################################   << START INPUT >>

# GLOBAL parameters
numHyp        <-
    4       # number of test hypotheses for FWER control
alphaTotal    <- 0.025   # one-sided total alpha
mtParam       <- 0.4     # study specific parameter for MT procedure

pdigits       <-
    5       # number of digits to report for p-value boundary
idigits       <-
    2       # number of rounding digits for information fractions
plotInPercent <-
    FALSE   # data availability at IA in per cent relative to maxN
Tmax_atPlot   <- 60      # time limit at plot

# Enrollment (this is aux to define enrollment per hypothesis below,
# (might need enrollment per hypothesis for sub-population analysis)
enrollmentAll <-
    tibble(stratum = "All",
           duration = 250 * 2 / 25,
           rate = 25)

# main input tibble, 1 row per hypothesis
inputD <- tibble::tibble(
  id  = paste0("H", 1:numHyp, sep = ""),
  # hypothesis id
  
  tag = c(# hyp tags, used in graph and output tables
    "PFS B+",
    "PFS",
    "ORR",
    "PRO"),
  
  # the following 3 fields 'regiment', 'ep', and 'suffix' are paste together
  # into 'descr' field for the input table defining hypotheses, 'tblInput'
  # either of them can be skipped
  regiment = rep("DrugX" , each = numHyp),
  ep     = c("PFS", "PFS", "ORR", "PRO"),
  suffix = c("BM+", "all", "all", "all"), #  e.g., for subgroups

  type = c("primary", "primary", "secondary", "secondary"),
  # hypothesis type
  w  = c(1, 0, 0, 0),
  # initial weights in graph MT procedure
  
  # define spending functions, use NULL if no group sequential test for Hi
  grSeqTesting = list(
    H1 = list(sfu = sfPower, sfupar = 2),
    H2 = list(sfu = sfLDOF, sfupar = NULL),
    H3 = NULL,
    H4 = NULL
  ),
  
  # "isSpec" and "hypN" would be use to derive information fractions, 'infoFr',
  # and timing,'iaTiming' (calendar time since study start), for the analyses
  
  
  iaSpec = list(
    # for each hypothesis, set criteria that trigger analyses by
    # a list( A1_list, A2_list, ..., Aj_list), where
    # Aj_list = list( H = 1, atIF = 0.5) means that for that hyp analysis
    # Analysis j takes place when H1 at 0.5 information fraction
    
    list(A1 = list(H = 2, atIF = 0.70), A2 = list(H = 2, atIF = 1)),
    list(A1 = list(H = 2, atIF = 0.70), A2 = list(H = 2, atIF = 1)),
    list(A1 = list(H = 2, atIF = 1)),
    list(A1 = list(H = 2, atIF = 1))
  ),
  
  # Set total information, N, for a given hypothesis (sample size or events)
  # leave NA, if enrollment and iaSpec would define N
  hypN  = c(NA, 350, NA, NA),
  
  # In some cased would need to define 'infoFr' and 'iaTime' explicitly
  # infoFr = list(
  # ),
  # calendar time of analysis
  # iaTime =  list(),
  
  # To define hypothesis test statistics Zi ~ N( ., 1) use 'endpointParam'
  # Class of 'endpointParam' is used to derive effect delta and standardized effect
  # Standardized effect size is used for power calculation
  # Several options are available to set test for binary endpoint
  # Also, Using 'enrollment' and 'iaSpec'  calculate information fractions
  endpointParam = list(
    structure(
      list(
        p1            = 0.60 * log(2) / 10,
        p2            = log(2) / 10,
        dropoutHazard = -log(1 - 0.05) / 12
      ),
      class             = "tte_exp"
    ),
    structure(
      list(
        p1            = 0.70 * log(2) / 15,
        p2            = log(2) / 15,
        dropoutHazard = -log(1 - 0.05) / 12
      ),
      class             = "tte_exp"
    ),
    structure(list(
      p1            = 0.85,
      p2            = 0.70,
      maturityTime  = 6
    ),
    class             = "binomial_pooled"),
    structure(list(
      p1            = 0.45,
      p2            = 0.10,
      maturityTime  = 3
    ),
    class             = "normal")
  ),
  allocRatio = 1,
  # relative allocation ratio trt/control
  prevalence = c(0.66, 1, 1, 1),
  enrollment = lapply(prevalence, function(a) {
    modify_at(enrollmentAll, "rate", ~ {
      a * .x
    })
  })
)

# define graphical testing procedure
graphProc <- function(s, hypNames = NULL) {
  # s - split parameter
  m <- matrix(0, numHyp, numHyp)
  m[1, 2] <-  1
  m[2, 3] <- 1 - s
  m[2, 4] <- s
  m[3, 4] <- 1
  m[4, 3] <- 1
  if (!is.null(hypNames)) {
    colnames(m) <- rownames(m) <- hypNames
  }
  graph <-
    new("graphMCP", m = m, weights = inputD$w)  #  note that init weight defined in 'inputD'
  return(graph)
}
G <-
  graphProc(mtParam, hypNames = paste(inputD$id, inputD$tag, sep = ": "))

# call to depict the graphical testing procedure (refer to manual for 'hGraph')
# location of nodes are defined via 'x', 'y' parameters
graphFigure <- gMCPLite::hGraph(
  nHypotheses     = numHyp,
  nameHypotheses  = paste(inputD$id, inputD$tag, sep = ": "),
  legend.name     = "Color scheme",
  # labels        = c("Regiment1", "Regiment2"), legend.position = c(.5, 0.2),
  # fill          = rep(1:2, each=numHyp/2), palette = c("cyan4", "lightblue"),
  halfWid         = 0.4,
  halfHgt         = 0.2,
  trhw            = 0.15,
  trhh            = 0.05,
  offset          = 0.2,
  size            = 4,
  boxtextsize     = 3.5,
  trdigits        = 3,
  # relative position of plots on MT graph
  x               = c(1, 3, 2, 4),
  y               = c(0, 0, -1, -1),
  alphaHypotheses = getWeights(G),
  m               = getMatrix(G),
  wchar           = "w"
)
###############################################   << END INPUT >>
```

```{r processInput, include=TRUE, echo=FALSE, message=FALSE}
checkInput(inputD, G)    # check the inputs TODO
main_objects <- exec_calc(inputD)
D           <- main_objects$D
ia_details  <- main_objects$ia_details
hyp_testing <- main_objects$hyp_testing_dataset
```
## Introduction 

With a `r enrollmentAll |> pull(duration) |> sum()`-month accrual period, 
the total sample size planned for the study is 
`r enrollmentAll |> mutate(n=duration*rate) |> pull(n) |> sum() |> ceiling()`. 

## Multiplicity Adjustment

The multiplicity strategy follows the graphical approach for group sequential 
designs of Maurer and Bretz (2013) 
which provides strong control of type 1 error.
The procedure takes into account both sources of multiplicity: 
multiple hypothesis tests (e.g., across primary and secondary endpoints) and 
multiple analyses planned for the study (i.e., interim and final analyses).

There are two key components that define this approach  

* Testing algorithm for multiple hypotheses specified by the graphical representation 
* Repeated testing of some hypotheses using the alpha-spending function methodology

The multiplicity strategy will be applied to the 
`r sum(D$type == "primary")`  primary superiority hypotheses 
( 
`r D %>% filter(type=="primary") %>% dplyr::select(descr) %>% unlist() %>% combine_words()`
)
and `r sum(D$type == "secondary")` key secondary superiority hypotheses
(
`r  D %>% filter(type=="secondary") %>% dplyr::select(descr) %>% unlist() %>%combine_words()`
). 
[Table @tbl-inputTable] summarizes the hypotheses specifying alpha-spending functions
(for hypotheses to be tested group sequentially) together with the
effect sizes and planned maximum statistical information 
(sample size or number of events). 

```{r inputTable, include=TRUE, echo=FALSE, results='markup'}
#| label: tbl-inputTable
#| tbl-cap: "Summary of Primary and Key Secondary Hypotheses"
tblInput <- D %>%
    dplyr::select(id, descr, type, w, grSeqTestingCh, deltaStr, hypN) %>%
    dplyr::rename(
        'Label'                    = id,
        'Description'              = descr,
        'Type'                     = type,
        'Initial weight'           = w,
        'Group Sequential Testing' = grSeqTestingCh,
        'Effect size'              = deltaStr,
        'n' = hypN
    )
# adding footnote information
names(tblInput)[6] <-
    paste0(names(tblInput)[6], footnote_marker_symbol (1))
names(tblInput)[7] <-
    paste0(names(tblInput)[7], footnote_marker_symbol (2))

if (is_html_output()) {
    tblInput  %>%
        kable("html", escape = F, align=rep("l",5), caption = "Summary of Primary and Key Secondary Hypotheses") %>%
        kable_styling() %>% 
        footnote(symbol = 
                     c(
                         "Mean difference for binary and continouos endpoints or hazard ratio (HR) for TTE endpoints",
                         "Sample size or number of events for TTE endpoints"
                     )
        )
} else if (is_latex_output()) {
    tblInput %>% 
        mutate_all(linebreak) %>%  
        kable("latex", booktabs = T, escape = F, longtable = TRUE 
          #    caption = "Summary of Primary and Key Secondary Hypotheses"
        ) %>%
        kable_styling(latex_options = c("hold_position", "repeat_header"))
    #%>% 
    # pack_rows(index = table(fct_inorder(df$hypNames)))
} else if (knitr::pandoc_to("docx")){
    require(flextable)
    df <- data.frame(lapply(tblInput, function(x) {gsub("<br>", "\n", x)}), stringsAsFactors = F)
    flextable(df)
}

```

[Figure @fig-timelinePlot] provides details as for statistical information
projected to be available (in percentage relative to maximum) versus time since
the trial start by the endpoint types. The vertical lines on the figure mark
times on the interim analyses.

The overall type I family-wise error rate for `r numHyp` hypotheses, over all
(interim and final) analyses, is controlled to `r alphaTotal*100`% (one-sided).

[Figure @fig-MTgraph] shows the graph where the hypotheses of interest are
represented by the elliptical nodes. Each node has the hypothesis weight
assigned to it (denoted by $w$). A particular value of $w$ sets the local
significance level associated with that hypothesis (which is equal to 
`r alphaTotal`$w$). The graphical approach allows local significance levels to
be recycled (along arrows on the graph) when a given hypothesis is successful
(i.e., the corresponding null hypothesis is rejected) at interim or final
analyses. Each arrow specifies the fraction of $w$ (by the number attached to
it) to be transferred from the source node to the destination node. This
"alpha-propagation" results in a corresponding increase of the local
significance level of the destination node. [Figure @fig-MTgraph] defines the
initial configuration of the local significance levels and the directed edges
(arrows). Particularly, the initial weight assignment for 
`r combine_words(D$descr[D$w>0])` is set to `r combine_words(D$w[D$w>0])`,
respectively.

```{r MTgraph, fig.cap="Graph Depicting Multiple Hypothesis Testing Strategy.", echo=FALSE, fig.align="center",fig.height=4, fig.width=6}
#| label: fig-MTgraph
#| fig-cap: "Graph Depicting Multiple Hypothesis Testing Strategy"
graphFigure

```

The testing algorithm codes a series of graph transformations which happens at
each successful clearing of a hypothesis as described in Maurer and Bretz
(2013). During an execution of the procedure, different scenarios as for local
significance levels emerge in an iterative manner.

## Interim Analyses

::: {.panel-tabset}

### IA by Hypothesis

[Table @tbl-iaDetailsTableA] and [Table @tbl-iaDetailsTableB] summarize the the planned interim analyses.

```{r iaDetailsTableA, include=TRUE, echo=FALSE, results='markup'}
#| label: tbl-iaDetailsTableA
#| tbl-cap: "Summary of Interim Analyses (by hypotheses)" 
tblAnalysesA <- ia_details                                    %>% 
    dplyr::select(id_tag, ia, criterion, iaTime, n.I, infoFr) %>% 
    dplyr::rename(
        "Hypothesis Analysis"    = ia,
        "Criteria for Conduct"   = criterion,
        "Targeted Analysis Time" = iaTime,
        "n"                      = n.I,
        "Information Fraction"   = infoFr
    )
names(tblAnalysesA)[5] <- paste0(names(tblAnalysesA)[5], footnote_marker_symbol (2))

if (is_html_output()) {
    tblAnalysesA[,-1] %>%
        dplyr::mutate(across(where(is.numeric), ~round(.x,2))) %>%
        kable("html", escape = F 
        # caption = "Summary of Interim Analyses (by hypotheses)"
        ) %>%
        kable_styling(position = "center", full_width = FALSE) %>%
        pack_rows( index=table(fct_inorder(tblAnalysesA$id_tag))) %>%
        footnote(symbol = 
                     c(
                         "Sample size or number of evetns for TTE endpoints"
                     )
        )
} else if (is_latex_output()) {
} else if (knitr::pandoc_to("docx")){
    require(flextable)
}
```															 

### IA by Calendar Time

```{r iaDetailsTableB, include=TRUE, echo=FALSE, results='markup'}
#| label: tbl-iaDetailsTableB
#| tbl-cap: "Summary of Interim Analyses (by calendar analysis)"
tblAnalysesB <- ia_details                                       %>% 
    dplyr::arrange(ia_ind, id_tag)                               %>%
    dplyr::select(ia_ind, id_tag, criterion, iaTime, n.I, infoFr)        %>% 
    dplyr::mutate(
        ia_ind = paste0("Data cut-off #",ia_ind)
        # n_str  = paste0(n.I," (", round(infoFr,idigits)*100, "%)")
    ) %>%
    dplyr::rename(
        "Analysis"               = ia_ind,
        "Hypothesis"             = id_tag, 
        "Criteria for Conduct"   = criterion,
        "Targeted Analysis Time" = iaTime,
        "n"                      = n.I, 
        "Information Fraction"   = infoFr
    )

names(tblAnalysesB)[5] <- paste0(names(tblAnalysesB)[5], footnote_marker_symbol (2))

if (is_html_output()) {
    groupingVec <- tblAnalysesB %>% 
        dplyr::mutate(across(where(is.numeric), ~round(.x,1))) %>%
        dplyr::mutate(
            `Targeted Analysis Time` = paste0("time = ",`Targeted Analysis Time`),
            `Criteria for Conduct`   = paste0("Criteria: ",`Criteria for Conduct`)
        ) %>%
        dplyr::select(`Analysis`,`Targeted Analysis Time`, `Criteria for Conduct`) %>% 
        tidyr::unite(col = calAnalysis, sep=", ")
    
    tblAnalysesB[,c(2,5,6)] %>%
        kable("html", escape = F, 
        # caption = "Summary of Interim Analyses (by calendar analysis)",
        align = c('lrr')) %>%
        kable_styling(position = "center", full_width = FALSE) %>%
        pack_rows( index = table(groupingVec))%>%
        footnote(symbol = 
                     c(
                         "Sample size or number of evetns for TTE endpoints"
                     )
        )
} else if (is_latex_output()) {
} else if (knitr::pandoc_to("docx")){
    require(flextable)
}

```															 

### Enrollment and Data Availability Plot

```{r timelinePlot, fig.cap="Timelines.", echo=FALSE, fig.align="center",fig.height=6, fig.width=9}
#| label: fig-timelinePlot
#| fig-cap: "Timelines"
dataAvailPlot <- plot_iaTiming( D %>% distinct(endpointParam, .keep_all = TRUE), 
                                enrollment = enrollmentAll, Tmax=Tmax_atPlot, plotInPercent = plotInPercent)
plot(dataAvailPlot)
```

:::

## Hypothesis Testing

::: {.panel-tabset}

### Scenarios 
For each hypothesis, [Table @tbl-graphTable] gives all possible scenarios for
the local significance levels in the first column, the corresponding $w$ in the
second column, and listing of scenarios as for what hypothesis testing needs to
be successful in the third column.

```{r graphTable, include=TRUE, echo=FALSE, results='markup'}
#| label: tbl-graphTable
#| tbl-cap: "List of possible local alpha levels following the graphical testing procedure"
knit_MT_table(hyp_testing, digits=5)
```

### Bounderies and Power 
[Table @tbl-grSeqTable] details the procedure regarding the hypothesis testing
at the interim and final analyses. If for a given hypothesis group sequential
testing is planned, the table provides the nominal p-value boundary derived from
the given alpha-spending function and the information fractions. This boundary
will be compared to the observed p-values calculated for the test statistics at
the corresponding analyses. The timing of analyses is expressed in terms of
statistical information fractions, i.e., current analysis information relative
to the total plan information for that hypothesis test. Also, the table reports
power (cumulatively over analyses) assuming hypotheses' effect sizes from [Table
@tbl-inputTable].

```{r grSeqTable, include=TRUE, echo=FALSE, results='markup'}
#| label: tbl-grSeqTable
#| tbl-cap: "Efficacy p-value Boundaries"
knit_MT_grSeq_table(hyp_testing, digits=5)
```

### Spending Functions

[Figure @fig-plotSF] visualizes alpha-spending functions profiled by local
significance levels available for hypotheses describing all potential scenarios
needed during an execution of the multiple testing procedure.

```{r plotSF, eval=TRUE, echo=FALSE, fig.height=11, fig.width=10}
#| label: fig-plotSF
#| fig-cap: "Alpha-spending functions"

unSF <- unique( dplyr::select(hyp_testing,alpha,sfu,sfupar)) %>% drop_na(sfu) 
tGrid <- seq(0,1,0.1)
sfDat <- pmap_dfr(unSF,function(sfu,sfupar,alpha){
    data.frame(
        alpha =alpha,
        t = tGrid,
        do.call(sfu,list(alpha,t=tGrid,sfupar))[c("name","spend","param","parname")]
    )    
}) %>% 
    mutate(
        Spending_function = ifelse(parname=="none",name, paste(name, parname,"=",param)),
        # Spending_function = name,
        alpha_level = factor(round(alpha,5))
    )

ggplot( sfDat, aes(x=t, y=spend, linetype = Spending_function, colour = alpha_level)) + 
    facet_wrap( ~Spending_function ,ncol=1)+
    geom_line() +
    labs(x="Informatin fraction", y="Cumulative alpha")+
    theme(
        plot.title = element_text(hjust = 0),
        legend.position="bottom",
        legend.direction = "vertical",
        legend.text = element_text (size=12),
        legend.title=element_text(size=12),
        axis.text = element_text(size=12),
        axis.text.x = element_text(hjust=1),# angle=45
        axis.title = element_text(size=14),
        strip.text.x = element_text(size = 12)
    )

```

:::

## References 
Maurer W, Bretz F. Multiple testing in group sequential trials using graphical
approaches. Statistics in Biopharmaceutical Research. 2013;5(4):311-320.
